# Exploring AI Bias Through SHAP-Based Interpretation of a Machine Learning Model

This project investigates potential bias in AI-driven hiring recommendations by training an XGBoost classifier on two synthetic datasets generated by different AI systems (ChatGPT and DeepSeek) and interpreting the model’s predictions using SHAP (SHapley Additive exPlanations). The analysis explores how features such as Age, Gender, Country, and professional attributes influence outcomes.

- Repository: naji-naji/Exploring-AI-Bias-Through-SHAP-Based-Interpretation-of-a-Machine-Learning-Model
- Primary language: Jupyter Notebook
- Notebook-first workflow

## Access The Analysis
- Main notebook: [case_study_notebook.ipynb](https://github.com/naji-naji/Exploring-AI-Bias-Through-SHAP-Based-Interpretation-of-a-Machine-Learning-Model/blob/main/case_study_notebook.ipynb)

## About The Data
Two CSV files contain synthetically generated candidate profiles and labels:

- [Test Data - ChatGPT.csv](https://github.com/naji-naji/Exploring-AI-Bias-Through-SHAP-Based-Interpretation-of-a-Machine-Learning-Model/blob/main/Test%20Data%20-%20ChatGPT.csv)
- [Test Data - DeepSeek.csv](https://github.com/naji-naji/Exploring-AI-Bias-Through-SHAP-Based-Interpretation-of-a-Machine-Learning-Model/blob/main/Test%20Data%20-%20DeepSeek.csv)

Columns
- Age (numeric)
- Gender (categorical)
- Country (categorical)
- Number of projects completed (numeric)
- Years of experience (numeric)
- Industry (categorical)
- Education level (categorical)
- Certifications count (numeric)
- Hire For Senior Role (label; Yes/No)

Notes
- Data is synthetic and created for research/illustration only.
- Sensitive/protected attributes (e.g., Gender, Age, Country) are present to enable bias analysis—handle with care in real-world settings.

## Goals
1. Train an XGBoost classifier to predict “Hire For Senior Role” from candidate attributes.
2. Use SHAP and importance metrics to:
   - Quantify global feature importance.
   - Visualize per-feature effect directions and magnitudes.
   - Examine local explanations for individual predictions.
3. Compare patterns across datasets generated by two different AI systems and discuss implications for bias and fairness.
   
